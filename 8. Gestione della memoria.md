# Introduzione
Esistono due filosofie di gestione della memoria che un linguaggio di programmazione può seguire:
- gestione manuale, come in C. Il programmatore è Dio e deve avere tutte le libertà che vuole.
- gestione automatica, come in Java e Python. Esistono approcci differenti:
	- **Reference counting**, usato da Perl e PHP
	- **Garbage collector**, usato da Java

Python usa sia ref counting che garbage collector.

## Reference counting
Quando deallochiamo la memoria (nel caso di Python si tratta dell'heap)?

Irraggiungibilità **sintattica**:
```Python
a = 1
a = 2
```
`1` non è più raggiungibile mediante `a`

Irraggiungibilità **semantica**: un pezzo di codice non verrà mai eseguito. Esistono euristiche che cercano di stimare questo, ma tradizionalmente non si usa.

Idea: possiamo aggiungere un contatore ad ogni oggetto creato, incrementandolo ad ogni nuovo riferimento, decrementandolo ogni volta che si perde un riferimento

#Attenzione il gestore della memoria non è perfetto. I **riferimenti circolari** sono un problema.

Possibile soluzione: introdurre un doppio contatore che conteggi i **riferimenti forti** e quelli **deboli** (circolari). Il contatore delle referenze deboli tiene conto del fatto che l'oggetto è referenziato altrove. Introduce overhead, soprattutto nel caso in cui le dipendenze cicliche siano *a catena*.

## Garbage collector
Due categorie:
- tracing
- generazionali

Quando eseguo il GC? ogni N secondi (Java) o ogni volta che superi una soglia di memoria (Python)
## Tracing
Partendo dagli oggetti radice segue a cascata tutte le referenziazioni.

Oggetti radici:
- variabili globali
- variabili locali
- argomenti della funzione

Anche in questo caso si risolve il problema dell'irraggiungibilità sintattica.

Esistono diversi algoritmi di tracing, elencati qui sotto.
### Mark and sweep
Navigo il grafo delle reference. Ogni oggetto incontrato viene marcato. Libero la memoria di tutti gli oggetti non marcati.

### Tricolor Marking
È un algoritmo che organizza gli oggetti in:
- **white**: candidati alla rimozione.
- **gray**: referenziati da oggetti radice, ma non sono ancora state analizzate le reference uscenti, si salveranno sicuramente finendo le black.
- **black**: oggetti non a rischio. Sono raggiungibili da oggetti radice e hanno riferimenti a oggetti gray o white.

Algoritmo:
1. black vuoto, white pieno
2. tutti gli oggetti radice nel gray
3. scelgo un oggetto dal gray set
4. visito le reference uscenti e sposto gli oggetti man mano nel gray set
5. L'oggetto viene spostato nel black.

Alla fine libero la memoria di tutti gli oggetti nel white set.

### Tecniche di rilascio della memoria
1. **in movimento**: copio tutti gli oggetti raggiungibili in una nuova area di memoria e libero le altre. Meno frammentazione. Compatto la memoria.
2. **non in movimento**: rilascio le zone di memoria degli oggetti non raggiungibili. Frammentazione.

Avere la memoria compatta aiuta nel momento dell'allocazione, perché non va cercato uno spazio capace di ospitare l'oggetto, ma anche a livello hw grazie al caching (efficienta l'uso delle cache)

## Generational
I garbage collector generazionali si basano sull'ipotesi, avvallata da studi scientifici, che gli oggetti più nuovi sia più probabile che vengano dereferenziati da lì a breve.

Questo tipo di GC divide gli oggetti in fasce di vecchiaia. Le generazioni più nuove sono controllate con una delle tecniche viste fin'ora più di frequente, man mano che invecchiano la frequenza di controllo diminuisce.

Generazioni:
- Eden (oggetti appena creati)
- Survivor (sopravvissuti a più cicli):
	- Survivor 2
	- Survivor 1: sopravvissuti a più cicli di S2
- Old: oggetti immortali o considerati tali

Ogni volta che un gruppo di oggetti supera un certo periodo di sopravvivenza viene invocato il garbage collector.

Ogni gruppo di oggetti porta con se il numero di iterazioni del GC che ha superato senza che venissero eliminati.

JVM memory layout: `| Perm |      Old     | S1 | S2 |  Eden  |`

La memoria viene libera da un'intera area quando (quasi) tutti gli oggetti sono promossi alla generazione più vecchia.

#Nota che se la frequenza del controllo è determinata da una soglia in termini di memoria, la porzione Eden sarà minore delle altre, per invocare più frequentemente il GC.

## Approcci ibridi
Minor cycle: fatto frequentemente -> generational
Major cycle: fatto ogni tanto -> mark and sweep

# In Python
Al momento si usa un approccio ibrido (Cython):
- reference counting
- generationa GC

Questo dipende da versione e interprete. Esistono diversi interpreti, scritti in linguaggi differenti:
- Cython - C
- Jython - Java
- PyPy - Python

## API
Modulo `gc`

```Python
gc.enable()
gc.disable()

gc.get_threshold()  # Ritorna le soglie per le tre generazioni
```

```Python
var = 'azz'
sys.getrefcount(var)  # 2
```

## Profilazione della memoria
OS-based: come `top`, ma poco granuali
Python-ingtegrated: `tracemalloc` e `memory-profiler`

Il primo è di più facile utilizzo:
```Python
import tracemalloc
tracemalloc.start()
...
current, peak = tracemalloc.get_traced_memory()  # current utilizzo corrente e peak utilizzo di picco precedente
tracemalloc.stop()
```

## Allocazione in Python
In Python viene usato solo l'heap. Usare un oggetto piccolo, banalmente un intero, richiede l'allocazione dello spazio per un oggetto. Sarebbero tante malloc consecutive. Le malloc sono costose.

L'interprete agisce da filtro verso il SO in modo da ridurre allocazioni e deallocazioni ad esso richieste. Questo viene effettuato preallocando grandi blocchi di memoria. L'interprete si tiene un heap privato.

L'allocatore di Python gestisce la memoria nel seguente modo:
- per oggetti molto grandi (> 512 bytes) si chiama la `malloc`
- per oggetti piccoli si passa per l'allocatore interno

Le zone di memoria gestite dall'allocatore sono divise in:
- **arene**: gruppi di pool
- **pool**: dove risiedono gli oggetti, divisi in blocchi
- **blocchi** di dimensione prefissata ed uguale all'interno dello stesso pool

Le free vengono effettuate per arene, non faccio free più granulari

Quando si tenta di allocare un oggetto viene scelta l'arena più piena:
1. principio di spazialità: spero di potermelo portare in cache
2. spero di fare il free delle altre arene. Meno le tengo bilanciate più è probabile che una possa essere liberata

Ogni pool ha blocchi uguali tra loro. Se devo allocare un oggetto e non esiste nessun pool la cui dimensione dei blocchi sia uguale a quella richiesta, creo un nuovo pool.

Le arene sono create ogni qualvolta si saturino le altre.

