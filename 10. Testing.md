# Ciclo di sviluppo
>L'informatica è una sfida tra i programmatori, a fare codice sempre più robusto, e Dio, a fare gente sempre più stupida.

## Unit testing
È la prima fase di testing di un software, dove si provano le sue porzioni più piccole.

## V model
Idealmente rappresentato da una V speculare: da un lato abbiamo la fase implementativa, mentre dall'altra la fase di debugging; dall'alto al basso troviamo prima le feature di alto livello e poi i dettagli implementativi.

Lo unit testing va a stressare le funzioni di basso livello; a livelli intermedi troviamo test di **integrazione** e **aggregazione**; i test di livello più alto sono svolti dagli umani.

>L'obiettivo dello unit-testing è verificare che una funzione si stata implementata correttamente. È importante testare gli edge-case.

## Organizzazione dei test
I test vengono organizzati in **case** e **suite**.

Ogni **test case** verifica il comportamento di una unità contro uno o più input, mentre una suite raccoglie tutti i test.

Il test runner è un componente che esegue tutti i test in oggetto e verifica che siano stati passati.

# unittest
È il modulo (framework) per fare unit-testing in Python: permette di definire test, raggrupparli in suite e lanciarli mediante il runner.

Per ogni test case creiamo una classe che eredita da `unittest.TestCase`. Scritti i test, possiamo lanciarli con `unittest.main()`

Il main trova tutte le classi che hanno ereditato da `TestCase` e lancia ogni metodo il cui nome include il prefisso `test`. Dentro al metodo si lancia la funzione in oggetto di testing e se ne verifica il valore di ritorno.

Diverse assert sono messe a disposizione dalla classe `TestCase`:
- `assertTrue`/`assertFalse`
- `assertIs`/`assertIsNot`
- `assertEqual`/`assertNotEqual`
- `assertIn`/`assertNotIn`
- `assertIsInstance`/`assertNotIsInstance`

Un test può avere 3 esiti: OK se tutti i test sono superati, FAIL se li test non è passato o è stata sollevata un'`AssertionError`, ERROR se è stata lanciata un'eccezione diversa da quest'ultima.

## Concetti
Supporta i seguenti concetti:
- **test fixture** rappresenta la preparazione al test e le seguenti operazioni di pulizia. Vengono instaurate connessioni, creati oggetti Proxy verso DB e aperti file. (fixture = impianto)
- **test case** è l'unità fondamentale dei test. Verifica che ci sia una risposta specifica ad un determinato insieme di input.
- **test suite** è una collezione di test case, test suite o entrambi. Aggrega i test che devono essere eseguiti insieme.
- **test runner** orchestra l'esecuzione dei test. Può presentarsi sotto diverse forme.

## Metodi speciali
Sono metodi usati per inizializzare il test (text fixture):
- `setUp[Class]` nella variante `Class` viene eseguito una volta prima di ogni altro metodo che implementa un test. Nella variante senza `Class` viene chiamato prima di ogni test.
- `tearDown[Class]` come sopra, ma successivamente all'esecuzione del/dei test. Sia in caso di successo che di fallimento

## Esempio
```Python
import unittest

class TestString(unittest.TestCase):
	def test_upper(self):
		self.assertEqual('foo'.upper(), 'FOO')

	def test_isupper(self):
		self.assertTrue('FOO'.isupper())
		self.assertFalse('Foo'.isupper())

	...

if __name__ == "__main__":
	unittest.main()
```

Eseguendolo viene generato un report sulla correttezza degli assert eseguiti. Con l'opzione `-v` si ottiene un output più dettagliato.

Dalla riga di comando:
```bash
python -m unittest testmod1 testmod2 [...]
python -m unittest testmod.TestClass
python -m unittest testmod.TestClass.test_method
python -m unittest  # Esegue la funzionalità di Test Discovery *
```

\* vengono trovati tutti i test file che si trovano nella directory di primo livello specificata (implicitamente quella corrente): `-s, --start-directory`

Altre opzioni:
- `-p, --pattern` pattern dei testfile. Di default `test*.py`
- `-t, --top-level-directory` top-level directory del progetto, di default la start-directory

#Nota è vantaggioso separare il modulo dei test da quello dell'implementazione per diversi motivi: rimuoverlo dalla versione distribuita del software, eseguirlo standalone, modificarlo meno di frequente, i test per moduli scritti in C devono essere comunque separati - perché non essere consistenti?
## Assert supportati
- `assertEqual(a, b)` e `assertNotEqual(a, b)`
- `assertTrue(x)` e `assertFalse(x)`
- `assertIs(a, b)` e `assertIsNot(a, b)`
- `assertIsNone(x)` e `assertIsNotNone(x)`
- `assertIn(a, b)` e `assertNotIn(a, b)`
- `assertIsInstance(a, b)` e `assertIsNotInstance(a, b)`

Inoltre, con il context manager è possibile testare il sollevamento di eccezioni:
```Python
with self.assertRises(TypeError):
	'abba'.split(2)
```

## Skip test
I test possono essere saltati con il decoratore `@unittest.skip("msg")` anche in modo condizionale con `@unittest.skipIf(<condition>, "msg")`


# Test-driven development
> È una metodologia di sviluppo software che mira a scrivere codice minimale in grado di passare i test.

Idea: passare dalle features richieste al software ad un test che le verifichi è un procedimento meccanico.

Scrivere il codice è un processo meno vincolato. Passare i test indirizza verso il funzionamento e assicura che nuove feature non rompano vecchie feature

## Pair programming
Consiglio: programmatore e tester dovrebbero essere due figure distinte, agnostiche rispetto al lavoro del collega. Prende il nome di **pair programming**

## Errori di regressione
>Gli errori di regressione sono quegli errori che vengono introdotti modificando codice "vecchio" per aggiungere "nuove feature"

*Test esaustivi*: devono coprire la maggior parte dei casi, altrimenti poco efficaci

# Approfondimenti
#Vedi https://docs.python.org/3/library/doctest.html#module-doctest