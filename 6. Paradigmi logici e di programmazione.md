# Altri paradigmi di programmazione
## Paradigma funzionale
Nel paradigma funzionale lo stile assomiglia a quello matematico -> si utilizzano funzioni e semplici espressioni per ottenere risultati anche complessi.

Eg: LISP
## Paradigma logico
Nel paradigma logico si esprime il problema sotto forma di vincoli e, a partire da questi, l'interprete cerca di trovare una soluzione.

Sono tutti paradigmi Turing-completi: ovvero attraverso questi paradigmi si può risolvere qualsiasi problema.

Eg: ProLog

# Paradigma funzionale in Python
Che differenza c'è tra definizione e dichiarazione? Nella definizione si esplicita il nome e il tipo di una funzione, mentre nella dichiarazione

## Dichiarazioni
>È un paradigma in stile dichiarativo: si dichiara che una certa variabile, identificata da un nome e da un tipo, deve assumere il valore ritornato da una certa funzione.

Non invoco/sposto/... la funzione. Assegno valori che verranno potenzialmente generati in futuro.
## Pure functions
Le **funzioni pure** sono il secondo cardine di questo paradigma.
>Una **funzione pura** è una funzione in cui a parità di argomenti, viene restituito lo stesso risultato (*stateless*); inoltre, non ha effetti collaterali. 

Quindi  una funzione pura non ha stati interni (o almeno non sono modificabili); inoltre non ha effetti collaterali, proprio perché il concetto di "stato" viene perso.
## Cicli
In questo paradigma non si utilizzano cicli, solamente la ricorsione.

In Python la ricorsione potrebbe saturare lo stack, per questo viene imposto un limite massimo di chiamate ricorsive permsse. Questo limite può essere alzato:

```python
sys.setrecursionlimit(XXX)
```
## Immutable
In Python posso decidere di usare - accorgimento del programmatore - solo oggetti immutabili (chiamati *nomi*)

Oppure sta al programmatore non modificare il valore dei parametri in ingresso.

Scala è un linguaggio che viene eseguito sulla JVM e ha costrutti/keywords apposite per evitare di modificare il valore di oggetti mutabili
## Ordine superiore
Python è un linguaggio di ordine superiore: le funzioni possono diventare argomenti di funzioni.

## Eval, Exec & compile
### Eval
>È una funzione che valuta una espressione (non istruzione), passata sotto forma di stringa, a tempo di esecuzione. Si possono passare anche variabili del programma principale/chiamante; il passaggio può avvenire sia come variabili globali sia come variabili locali.

```Python
eval("print('ciao')")
eval("print('ciao')", globals, locals)
```

`globals` e `locals` sono definiti come dizionari.
#Prova `globals()` e `locals()` -> ritornati dizionari di funzioni e variabili definiti nei rispettivi scope.

Perché due scope? Per comodità nello scope globale vengono mantenuti valori definiti globalmente, mentre in quello locale variabili che potrebbero oscurare quelle presenti nello scope globale, per esempio definite dinamicamente sull'input dell'utente.

Il valore di ritorno di `eval` è il risultato dell'espressione valutata.

#Attenzione valutare a runtime qualsiasi stringa si voglia può implicare problemi di sicurezza.

Posso mitigare alcuni problemi con: `eval("open('/etc/passwd').read()", globals = {"open" = None})` dato che `open` è un metodo built-in

### Exec
>Come eval, ma molto più completo. Permette di eseguire bytecode, eseguire istruzioni (come l'import di moduli) e altro.

### Compile
>Permette di compilare un file o una stringa in bytecode.

```Python
compile(source, file, mode)
```

Se si vuole valutare la stringa, l'argomento file deve essere uguale a `"<string>"`

Modalità:
- exec - Se contiene delle istruzioni
- eval - Se contiene solo espressioni. Più leggero, non deve allocare della memoria
- single - Per istruzioni singole

## Functools
### Funzioni parziali
>Modulo utile alla programmazione funzionale. Fornisce funzioni di ordine superiore per eseguire operazioni comuni nella programmazione funzionale. Fornisce anche delle classi per rappresentare funzioni: `partial`, `partialmethod`

Le funzioni parziali sono funzioni in cui il valore degli argomenti è parzialmente specificato.

```python
def somma(x, y):
	return x+y

sommapartial = partial(somma, y=1)
# sommapartial è un oggetto di tipo funzione che acetta un solo argomento: x
```

Perché è utile alla programmazione funzionale? Harcodare gli argomenti permette di rimuovere lo stato che si andrebbe a passare alla funzione. É per questo che è un costrutto funzionale.

```Python
class A:
	def print_str(self, s):
		print(s)
	print_ciao = partialmethod(print_str, s='ciao')
```

### Funzione chiave
>Una funzione chiave, spesse volte usata in connubio con la funzione `sorted()`, da la possibilità di specificare secondo quale criterio ordinare gli elementi di un iterabile.

Una funzione chiave semanticamente restituisce un valore a partire da valori multipli.
Non è sempre facile come `lambda x: x[1]`. Potrebbe servire un ordinamento più complesso, basato per esempio su campi multipli (vedi esempio sotto). In questi casi è necessario usare la funzione di Functools `cmp_to_key`

```Python
def cmp_date(x, y):
	if x.year < y.year: return -1
	elif x.month < y.month: return -1
	else x.day < y.day: return -1

sorted(dates, key = cmp_to_key(cmp_date))
```

Implementata come una funzione che restituisce una classe in cui sono implementati (overridati) gli operatori di confronto, uguaglianza e diversità. L'unica cosa di cui `sorted` si preoccupa è che venga passato a `key` un oggetto invocabile. Nel caso di una funzione chiave questa è applicata sulla coppia di elementi da confrontare, per poi fare il confronto. Nel caso di un "oggetto chiave" (ad esempio ritornato da `cmp_to_key`) sono costruiti due oggetti a partire dai due elementi, quindi confrontati. La relazione d'ordine è stabilita grazie agli operatori di confronto sovrascritti dalla classe.

#Vedi https://github.com/python/cpython/blob/f9e6ce03953e9ee988d55324dc715b0ef2303cfb/Lib/functools.py#L207
### Total ordering
Il decoratore `@total_ordering` permette di ricavare i metodi di confronto mancanti, fornita l'implementazione di `__eq__` e uno tra:
- `__lt__`
- `__le__`
- `__gt__`
- `__ge__`

### LRU Cache
>È un decoratore che fa caching dei risultati di chiamate a funzione, in modo da riutilizzare il risultato quando gli argomenti sono analoghi a una delle entry in cache.

È implementato con una struttura associativa sui parametri attuali delle chiamate.
#Attenzione Deve essere una **funzione pura**, quindi deterministica

```Python
@lru_cache(maxsize = None)
def fibo(x):
 return fibo(x-1) + fibo(x-2)
```

Il parametro `maxsize` può essere utilizzato per passare un numero massimo di entry della struttura associativa.
## Itertools
>Fornisce funzioni per generare sequenze di dati
### Iteratori infiniti
```Python
count(10)  # Genera i numeri da 10 in poi
cycle([1, 2, 3])  # Cicla in modo infinito tra i valori
repeat('x')  # Ripete un oggetto per sempre
```
### Iteratori che modifica la sequenza
- `accomulate([1, 2, 3, 4])`: 1, 3, 6, 10
- `chain('az', 'zo')` 
- `zip_longes('ABC', 'xyz')`: Ax By Cz
- `starmap(pow, [(2, 3), (4, 2)])`: come il map ma applica l'operatore star agli argomenti. In questo caso è necessario in quanto la funzione ha firma `pow(base, exp)`
### Iteratori combinatori
```Python
permutations([1, 2, 3])
combinations([1, 2, 3], 2)  # 2 numero di elementi per raggruppamento
```
# Vantaggi
## Debugging
Il debugging classico di una funzione prevede di stampare gli argomenti della funzione, insieme allo stato interno.

Nel paradigma funzionale è più semplice.

Il risultato di un programma è il risultato di funzioni di funzioni di ...
#Nota il LISP veniva chiamato il *linguaggio delle parentesi*

## Ottimizzazione
Attraverso l'unrolling delle funzioni si possono ottimizzare sia precisione sia stabilità/precisione dell'espressione.

Struttura facilmente interpretabile, possibili parallelizzazioni.

Ottimizzazione in memoria: ogni valore passa per la catena di trasformazioni, non deve essere riversato in memoria principale.

Ottimizzazioni in performance:
- posso abbozzare una pipeline, a maggior ragione se ho più core. Ogni core è adibito ad una operazione.
- Posso parallelizzare mandando ogni valore su un flusso di esecuzione indipendente

## Lazy evaluation
Una composizione di funzioni verrà eseguita solo al bisogno:
- potenzialmente potrebbe non essere mai eseguita
- attendo la fine del programma per invocare una grossa composizione, nella speranza che qualcosa si potesse ottimizzare

## Conclusione
Particolarmente vantaggioso per gestire flussi di dati.

# Strumenti funzionali in Python
## List comprehension
>Costrutto sintattico per la creazione di liste o dizionari senza un ciclo for

```python
[x for x in iterable if condition else y]
```

Con for annidati:
```python
[x for iter1 in iter2 for x in iter1]
```

#Attenzione è da leggere da sinistra verso destra

## Lambda function
Le funzioni lambda (anonime) sono funzioni con argomenti e un risultato, senza nome. Esistono linguaggi basati esclusivamente sul lambda-calcolo.

## Filter & map
Per filtrare valori dispari:
```python
filter(lambda x: x%2, iterabile)
```

`filter` scarta tutti gli elementi il cui valore di ritorno della funzione è `False`

```python
map(lambda x: x*2, iterable)
```

Mappa ogni elementi di `iterable` nel suo doppio

# Altri paradigmi logici
Modo di approcciarsi al problema.
## MapReduce
Paradigma distribuito per la computazione dati.
#Esiste un framework di Google con lo stesso nome

Diviso in due fasi:
1. Mappatura dei dati -> filtraggio ed elaborazione sui singoli elementi
2. Riduzione -> aggregazione dei risultato della prima fase

Le fasi avvengono in momenti e sistemi diversi. In particolare, il filtraggio avviene indipendentemente su ogni nodo. Non si può assumere la sequenzialità dei dati.

### Esempio
Es: estrarre tutti i prefissi da server che mantengono contatti telefonici

Primo approccio
```
1. | Node 1 |       | Node 2 |        ...         | Node N |
2.     |                |                             |
3.     v                v                             v
4.  |                    Aggregatore                      |
```
Difetti: supponiamo liste di prefissi da 1Gb: troppo carico su aggragatore. Necessaria verifica non-duplicità durante la riduzione.

Secondo approccio: divide et impera (o meglio, impera e aggrega) a più livelli. Ogni nodo di primo livello manda, a cascata, i dati a nodi intermedi, fino ad arrivare all'aggregatore finale.
### Implementazione
In Python esiste la funzione `reduce()` che fa parte della libreria `functools`.

Utilità in locale? supponiamo ad esempio di avere un DB grande diversi Tb su un sistema con memoria esigua. Potremmo splittarlo in chunk e, successivamente, applicare la funzione `reduce` a coppie di file, appoggiando via via il risultato in RAM.

Può inoltre essere utile se i dati arrivano al sistema come flusso. Posso ad esempio eseguire il reduce in tempi molto distanti tra loro, per non dover mantenere tutti i log di un sistema in memoria.